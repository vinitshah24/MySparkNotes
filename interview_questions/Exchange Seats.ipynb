{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfcb6c4-ef5f-496b-991a-8c25df56b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462caf9b-c916-48b5-8072-470f269b9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f3eb86-092e-4564-b889-d62f602312c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|  Alice|\n",
      "|  2|    Bob|\n",
      "|  3|Charlie|\n",
      "|  4|  David|\n",
      "|  5|    Eve|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [1, \"Alice\"],\n",
    "    [2, \"Bob\"],\n",
    "    [3, \"Charlie\"],\n",
    "    [4, \"David\"],\n",
    "    [5, \"Eve\"],\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf740eb-e236-4b7c-b496-1cc6dde8d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  2|    Bob|\n",
      "|  1|  Alice|\n",
      "|  4|  David|\n",
      "|  3|Charlie|\n",
      "|  5|    Eve|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DOES NOT WORK\n",
    "df1 = df.withColumn(\"id_change\", when(col(\"id\") % 2 == 1, col(\"id\") + 1).otherwise(col(\"id\") - 1))\n",
    "df1.select(col(\"id\").alias(\"id\"), \"name\").orderBy(\"id_change\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059f4c5f-de16-428b-9fab-b5714b743bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7438cce-7836-4f9a-a4de-be7f92cffc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+---------+\n",
      "| id|   name|prev_seat|next_seat|\n",
      "+---+-------+---------+---------+\n",
      "|  1|  Alice|     null|      Bob|\n",
      "|  2|    Bob|    Alice|  Charlie|\n",
      "|  3|Charlie|      Bob|    David|\n",
      "|  4|  David|  Charlie|      Eve|\n",
      "|  5|    Eve|    David|     null|\n",
      "+---+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = (\n",
    "    df\n",
    "    .withColumn(\"prev_seat\", lag(\"name\").over(Window.orderBy(\"id\")))\n",
    "    .withColumn(\"next_seat\", lead(\"name\").over(Window.orderBy(\"id\")))\n",
    ")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa477f8-c8e6-4d91-a564-7cd9d9a57448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------------+\n",
      "| id|original_set|exchanged_seat|\n",
      "+---+------------+--------------+\n",
      "|  1|       Alice|           Bob|\n",
      "|  2|         Bob|          name|\n",
      "|  3|     Charlie|         David|\n",
      "|  4|       David|          name|\n",
      "|  5|         Eve|           Eve|\n",
      "+---+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = (\n",
    "    df1\n",
    "    .withColumn(\"exchanged_seat\",\n",
    "                when(col(\"id\") % 2 == 1, coalesce(\"next_seat\", \"name\"))\n",
    "                .when(col(\"id\") % 1 == 1, coalesce(\"prev_seat\", \"name\"))\n",
    "                .otherwise(\"name\")\n",
    "               )\n",
    ")\n",
    "df2 = df2.withColumnRenamed(\"name\", \"original_set\").drop(\"next_seat\", \"prev_seat\", \"id_change\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dc12be-255d-43aa-be47-5cecf32c6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"student_seats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6e72b5-f37c-486c-b535-29b48e3efa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+--------+\n",
      "| id|original_seat|new_seat|\n",
      "+---+-------------+--------+\n",
      "|  1|        Alice|     Bob|\n",
      "|  2|          Bob|   Alice|\n",
      "|  3|      Charlie|   David|\n",
      "|  4|        David| Charlie|\n",
      "|  5|          Eve|     Eve|\n",
      "+---+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    name AS original_seat,\n",
    "    CASE\n",
    "        WHEN id % 2 = 1 \n",
    "            THEN COALESCE(LEAD(name) OVER (ORDER BY id), name)\n",
    "        WHEN id % 2 = 0 \n",
    "            THEN COALESCE(LAG(name) OVER (ORDER BY id), name)\n",
    "        ELSE name\n",
    "    END AS new_seat\n",
    "FROM student_seats\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1b368-30b4-4419-8b2b-6a4d574f9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
