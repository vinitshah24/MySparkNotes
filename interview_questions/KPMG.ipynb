{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b77c0b-152b-4306-b565-7a29a5cbf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd0b71c-ed69-451e-8b00-74791d3f1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fb14a-b10e-49ae-93d3-5d6846f96bd6",
   "metadata": {},
   "source": [
    "### Q1: Explode Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f63ade-a791-432c-b9be-663910737494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|   name|            hobbies|\n",
      "+-------+-------------------+\n",
      "|  Nadal|[Badminton, Tennis]|\n",
      "|Federer|  [Tennis, Cricket]|\n",
      "|  Novak|         [Baseball]|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"Nadal\", [\"Badminton\", \"Tennis\"]],\n",
    "    [\"Federer\", [\"Tennis\", \"Cricket\"]],\n",
    "    [\"Novak\", [\"Baseball\"]],\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"name\", \"hobbies\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2344e90-ce7e-443a-9ada-76945d4f4b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hobbies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3e6797-3b9e-4220-988f-0e04a079908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|   name|    hobby|\n",
      "+-------+---------+\n",
      "|  Nadal|Badminton|\n",
      "|  Nadal|   Tennis|\n",
      "|Federer|   Tennis|\n",
      "|Federer|  Cricket|\n",
      "|  Novak| Baseball|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.withColumn(\"hobby\", explode(col(\"hobbies\"))).select(\"name\", \"hobby\").show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe58c5-a6d0-446d-a38b-75e72c7fe73a",
   "metadata": {},
   "source": [
    "### Q2: Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de986e49-e3f2-46f8-a8ee-cbf1ee68c837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+\n",
      "|   city1|  city2|     city3|\n",
      "+--------+-------+----------+\n",
      "|New York|       |     Texas|\n",
      "|        |Georgia|      null|\n",
      "|    null|       |New Jersey|\n",
      "+--------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"New York\", \"\", \"Texas\"],\n",
    "    [\"\", \"Georgia\", None],\n",
    "    [None, \"\", \"New Jersey\"],\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"city1\", \"city2\", \"city3\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72b814d-b1c2-4f59-ad86-78c16ee263fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      city|\n",
      "+----------+\n",
      "|  New York|\n",
      "|   Georgia|\n",
      "|New Jersey|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    coalesce(\n",
    "        when(col(\"city1\") == \"\", None).otherwise(col(\"city1\")),\n",
    "        when(col(\"city2\") == \"\", None).otherwise(col(\"city2\")),\n",
    "        when(col(\"city3\") == \"\", None).otherwise(col(\"city3\")),\n",
    "    ).alias(\"city\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588f646-eae8-444f-a4df-618ef52533b0",
   "metadata": {},
   "source": [
    "### Q3 Date Functions and Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd29502-a05b-4842-b3de-50effa53d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-------+---------+------+\n",
      "|emp_id|emp_name|mgr_id|dept_id|salary_dt|salary|\n",
      "+------+--------+------+-------+---------+------+\n",
      "|   100|     Raj|  null|      1| 01-04-23| 50000|\n",
      "|   200|  Joanne|   100|      1| 01-04-23|  4000|\n",
      "|   200|  Joanne|   100|      1| 13-04-23|  4500|\n",
      "|   200|  Joanne|   100|      1| 14-04-23|  4020|\n",
      "+------+--------+------+-------+---------+------+\n",
      "\n",
      "+-------+---------+\n",
      "|dept_id|dept_name|\n",
      "+-------+---------+\n",
      "|      1|       IT|\n",
      "|      2|       HR|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (100, \"Raj\", None, 1, \"01-04-23\", 50000),\n",
    "    (200, \"Joanne\", 100, 1, \"01-04-23\", 4000),\n",
    "    (200, \"Joanne\", 100, 1, \"13-04-23\", 4500),\n",
    "    (200, \"Joanne\", 100, 1, \"14-04-23\", 4020),\n",
    "]\n",
    "salary_df = spark.createDataFrame(\n",
    "    data, [\"emp_id\", \"emp_name\", \"mgr_id\", \"dept_id\", \"salary_dt\", \"salary\"]\n",
    ")\n",
    "salary_df.show()\n",
    "\n",
    "data = [(1, \"IT\"), (2, \"HR\")]\n",
    "dept_df = spark.createDataFrame(data, [\"dept_id\", \"dept_name\"])\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce17993f-325c-407e-8f45-1af1a14e88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-------+---------+------+-------+---------+------+--------+------+-------+---------+------+\n",
      "|emp_id|emp_name|mgr_id|dept_id|salary_dt|salary|dept_id|dept_name|emp_id|emp_name|mgr_id|dept_id|salary_dt|salary|\n",
      "+------+--------+------+-------+---------+------+-------+---------+------+--------+------+-------+---------+------+\n",
      "|   100|     Raj|  null|      1| 01-04-23| 50000|      1|       IT|  null|    null|  null|   null|     null|  null|\n",
      "|   200|  Joanne|   100|      1| 01-04-23|  4000|      1|       IT|   100|     Raj|  null|      1| 01-04-23| 50000|\n",
      "|   200|  Joanne|   100|      1| 13-04-23|  4500|      1|       IT|   100|     Raj|  null|      1| 01-04-23| 50000|\n",
      "|   200|  Joanne|   100|      1| 14-04-23|  4020|      1|       IT|   100|     Raj|  null|      1| 01-04-23| 50000|\n",
      "+------+--------+------+-------+---------+------+-------+---------+------+--------+------+-------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    salary_df.alias(\"e\")\n",
    "    .join(dept_df.alias(\"d\"), col(\"e.dept_id\") == col(\"d.dept_id\"))\n",
    "    .join(salary_df.alias(\"m\"), col(\"e.mgr_id\") == col(\"m.emp_id\"), \"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d0c8363-56fa-4ab8-a4d3-d99bbd13dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+-----------+------------+------+\n",
      "|dept_name|mgr_name|emp_name|salary_year|salary_month|salary|\n",
      "+---------+--------+--------+-----------+------------+------+\n",
      "|       IT|    null|     Raj|       2023|           4| 50000|\n",
      "|       IT|     Raj|  Joanne|       2023|           4|  4000|\n",
      "|       IT|     Raj|  Joanne|       2023|           4|  4500|\n",
      "|       IT|     Raj|  Joanne|       2023|           4|  4020|\n",
      "+---------+--------+--------+-----------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df = df.select(\n",
    "    col(\"d.dept_name\"),\n",
    "    col(\"m.emp_name\").alias(\"mgr_name\"),\n",
    "    col(\"e.emp_name\"),\n",
    "    year(to_date(\"e.salary_dt\", \"dd-MM-yy\")).alias(\"salary_year\"),\n",
    "    month(to_date(\"e.salary_dt\", \"dd-MM-yy\")).alias(\"salary_month\"),\n",
    "    col(\"e.salary\"),\n",
    ")\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ca42d0-4365-4529-9004-ebd4f3c66adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+-----------+------------+--------------+\n",
      "|dept_name|mgr_name|emp_name|salary_year|salary_month|monthly_salary|\n",
      "+---------+--------+--------+-----------+------------+--------------+\n",
      "|       IT|     Raj|  Joanne|       2023|           4|         12520|\n",
      "|       IT|    null|     Raj|       2023|           4|         50000|\n",
      "+---------+--------+--------+-----------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    emp_df\n",
    "    .groupBy(\"d.dept_name\", \"mgr_name\", \"e.emp_name\", \"salary_year\", \"salary_month\")\n",
    "    .agg(sum(\"e.salary\").alias(\"monthly_salary\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667aa37e-e3f2-4b6e-a1c1-ad0a4a50fe14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
