{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Log #1\n",
    "```\n",
    "Stdoutput Caused by: \n",
    "org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 32 (parquet at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. \n",
    "...\n",
    "Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: Too large frame: 4410995563\n",
    "```\n",
    "### What does this mean?\n",
    "* When performing a `join` on multiple `DataFrame`s, data is usually shuffled in smaller chunks called `partitions`. \n",
    "* This errors indicates that the **partitions shuffled are too large**.\n",
    "\n",
    "### Solution\n",
    "* The default partition size is `200`. \n",
    "* Try to playing around with the `spark.sql.shuffle.partitions` parameter, use values that are a power of 2, ie. 2^11 = `2048`.\n",
    "* Increasing the number of partitions will decrease the size of each partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Log #2\n",
    "```\n",
    "Stdoutput py4j.protocol.Py4JJavaError: An error occurred while calling o3092.freqItems.\n",
    "Stdoutput : org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 43334 tasks (5.4 GB) is bigger than spark.driver.maxResultSize (5.4 GB)\n",
    "```\n",
    "### What does this mean?\n",
    "* The amount of data that you are pulling back to the driver to is large!\n",
    "* This is the result of performing some sort of `collect` which brings all the data to one processor, the driver.\n",
    "\n",
    "### Solution\n",
    "* If this is really what you want, then increasing the driver's heap might help.\n",
    "* Alternately if this isn't what you want, try instead of a `collect` use a `head`, `take`, etc. This will only take a collect a couple of rows to the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
